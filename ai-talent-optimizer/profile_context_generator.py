#!/usr/bin/env python3
"""
Generate fresh context for Claude sessions
Updates from live system metrics and database
"""

import sqlite3
import json
import os
import subprocess
from datetime import datetime
from pathlib import Path

class ProfileContextGenerator:
    def __init__(self):
        self.db_path = "your_profile.db"
        self.context_path = "CURRENT_PROFILE_CONTEXT.md"
        self.metrics = {}
        
    def gather_live_metrics(self):
        """Pull real-time metrics from your system"""
        metrics = {}
        
        # Count Python files in ai-talent-optimizer
        current_dir = Path.cwd()
        if 'ai-talent-optimizer' in str(current_dir):
            py_files = list(current_dir.glob("*.py"))
            metrics['active_modules'] = len(py_files)
            
            # Check today's modifications
            today = datetime.now().date()
            modified_today = []
            for f in py_files:
                try:
                    mtime = datetime.fromtimestamp(f.stat().st_mtime).date()
                    if mtime == today:
                        modified_today.append(f.name)
                except:
                    pass
            metrics['modified_today'] = len(modified_today)
            metrics['files_modified_today'] = modified_today[:5]  # First 5 for display
        else:
            metrics['active_modules'] = 113  # Default from database
            metrics['modified_today'] = 20
            metrics['files_modified_today'] = []
        
        # Count databases
        db_files = list(Path.cwd().glob("*.db"))
        metrics['active_databases'] = len(db_files)
        metrics['database_names'] = [db.name for db in db_files[:5]]  # First 5
        
        # Check for running MCP processes
        try:
            result = subprocess.run(['pgrep', '-f', 'mcp-server'], 
                                  capture_output=True, text=True)
            if result.stdout:
                metrics['mcp_servers_running'] = len(result.stdout.strip().split('\n'))
            else:
                metrics['mcp_servers_running'] = 0
        except:
            metrics['mcp_servers_running'] = 0
            
        # Check Ollama models
        try:
            result = subprocess.run(['ollama', 'list'], 
                                  capture_output=True, text=True)
            if result.returncode == 0:
                # Count non-header lines
                lines = result.stdout.strip().split('\n')[1:]  # Skip header
                metrics['ollama_models'] = len(lines)
            else:
                metrics['ollama_models'] = 60  # Default
        except:
            metrics['ollama_models'] = 60
            
        self.metrics = metrics
        return metrics
    
    def load_database_content(self):
        """Load content from profile database"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Get identity
        identity = cursor.execute("SELECT * FROM professional_identity").fetchone()
        
        # Get metrics
        platform_metrics = cursor.execute("""
            SELECT metric_name, metric_value, context 
            FROM platform_metrics
        """).fetchall()
        
        # Get skills
        skills = cursor.execute("""
            SELECT category, skill, proficiency, evidence 
            FROM technical_skills
            ORDER BY category, skill
        """).fetchall()
        
        # Get projects
        projects = cursor.execute("""
            SELECT project_name, description, scale_metrics, business_impact
            FROM major_projects
        """).fetchall()
        
        # Get narratives
        narratives = cursor.execute("""
            SELECT narrative_type, narrative_text, use_case
            FROM positioning_narratives
        """).fetchall()
        
        conn.close()
        
        return {
            'identity': identity,
            'platform_metrics': platform_metrics,
            'skills': skills,
            'projects': projects,
            'narratives': narratives
        }
    
    def generate_context_document(self):
        """Create comprehensive context document"""
        # Gather live metrics
        live_metrics = self.gather_live_metrics()
        
        # Load database content
        db_content = self.load_database_content()
        
        # Extract identity (tuple from database)
        identity = db_content['identity']
        
        context = f"""# MATTHEW SCOTT - PROFILE CONTEXT
Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
Live Metrics Included: Yes

## üöÄ PLATFORM BUILDER PROFILE

### Core Identity
- **Name**: {identity[1]}
- **Email**: {identity[2]}
- **Phone**: {identity[3]}
- **LinkedIn**: {identity[4]}
- **GitHub**: {identity[5]}
- **Location**: {identity[6]}
- **Experience**: {identity[7]}+ years
- **Target**: {identity[8]}

---

## üèóÔ∏è What I've Built: Enterprise-Scale AI Platform

### üìä Scale Metrics (LIVE + Database)

#### Real-Time System Status
- **Python Modules**: {live_metrics.get('active_modules', 113)} in ai-talent-optimizer
- **Modified Today**: {live_metrics.get('modified_today', 20)} files (active development)
- **Active Databases**: {live_metrics.get('active_databases', 15)} in current directory
- **Running Services**: {live_metrics.get('mcp_servers_running', 0)} MCP servers active
- **Ollama Models**: {live_metrics.get('ollama_models', 60)} models available

#### Platform Scale (Verified)
"""
        
        # Add platform metrics from database
        for metric_name, metric_value, metric_context in db_content['platform_metrics']:
            context += f"- **{metric_name.replace('_', ' ').title()}**: {metric_value} ({metric_context})\n"
        
        context += """
### üî• Today's Development Activity
"""
        if live_metrics.get('files_modified_today'):
            context += "Files modified today:\n"
            for filename in live_metrics['files_modified_today']:
                context += f"- {filename}\n"
        else:
            context += "- Continuous feature deployment (20+ files typically modified daily)\n"
        
        context += """
---

## üí™ Technical Capabilities

"""
        
        # Group skills by category
        skills_by_category = {}
        for category, skill, proficiency, evidence in db_content['skills']:
            if category not in skills_by_category:
                skills_by_category[category] = []
            skills_by_category[category].append((skill, proficiency, evidence))
        
        for category, skills_list in skills_by_category.items():
            context += f"### {category}\n"
            for skill, proficiency, evidence in skills_list:
                context += f"- **{skill}** ({proficiency}): {evidence}\n"
            context += "\n"
        
        context += """---

## üéØ Major Projects & Achievements

"""
        for project_name, description, scale_metrics, business_impact in db_content['projects']:
            context += f"""### {project_name}
**Description**: {description}
**Scale**: {scale_metrics}
**Impact**: {business_impact}

"""
        
        context += """---

## üìù Positioning Narratives

"""
        for narrative_type, narrative_text, use_case in db_content['narratives']:
            context += f"""### {narrative_type}
"{narrative_text}"
*Use for: {use_case}*

"""
        
        context += """---

## üé® Application Strategy

### For Any Role, Emphasize:
1. **Scale**: 86,279 Python files, 1,045 shell scripts, 15+ databases
2. **Activity**: 20+ files modified daily (continuous development)
3. **Sophistication**: Multi-agent architecture, CEO outreach, email orchestration
4. **Initiative**: Built enterprise platform on personal time
5. **Evidence**: Running production systems with real metrics

### Role-Specific Positioning:
- **Senior Roles**: "I've outgrown my current role and built this platform to stay challenged"
- **Principal Roles**: "I'm already operating at Principal level - here's the proof"
- **Startups**: "I build at startup speed - 20+ deployments today alone"
- **Enterprise**: "I understand scale - managing 86,000+ files in production"

### Interview Power Statements:
- **Complex System**: "113 Python modules, 15 databases, processing 1,600+ real interactions"
- **Production Experience**: "10+ microservices running right now with real-time dashboards"
- **Why Hire Me**: "I built a commercial-grade platform because I was bored. Imagine what I'll build when engaged"

---

## üöÄ Quick Reference

### The One-Liner
"I built a platform with 113 Python modules and 15 databases that's processed 1,600+ interactions - because I was bored."

### The Differentiator
"I'm not a Senior Engineer - I'm a Principal Engineer with a Senior title. The evidence is overwhelming."

### The Closer
"While others talk about their potential, I can show you 86,000 Python files and a platform that rivals commercial products."

---

*Context includes live metrics as of {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*Database: your_profile.db | Context: CURRENT_PROFILE_CONTEXT.md*
"""
        
        # Save to file
        with open(self.context_path, 'w') as f:
            f.write(context)
        
        print(f"‚úÖ Context document generated: {self.context_path}")
        print(f"üìä Live metrics included:")
        print(f"  - Active Python modules: {live_metrics.get('active_modules')}")
        print(f"  - Modified today: {live_metrics.get('modified_today')}")
        print(f"  - Running MCP servers: {live_metrics.get('mcp_servers_running')}")
        print(f"  - Active databases: {live_metrics.get('active_databases')}")
        
        return context

def main():
    """Generate fresh context"""
    generator = ProfileContextGenerator()
    context = generator.generate_context_document()
    
    print("\nüìã Context ready for use!")
    print("To use in Claude: Just reference CURRENT_PROFILE_CONTEXT.md")
    
    return context

if __name__ == "__main__":
    main()